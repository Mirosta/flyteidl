syntax = "proto3";

package flyteidl.plugins.kubeflow;

option go_package = "github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/plugins";

import "flyteidl/plugins/kubeflow/common.proto";

// Custom proto for plugin that enables distributed training using https://github.com/kubeflow/tf-operator
message DistributedTensorflowTrainingTask {
  // Worker replicas spec
  DistributedTensorflowTrainingReplicaSpec worker_replicas = 1;

  // Parameter server replicas spec
  DistributedTensorflowTrainingReplicaSpec ps_replicas = 2;

  // Chief replicas spec
  DistributedTensorflowTrainingReplicaSpec chief_replicas = 3;

  // RunPolicy encapsulates various runtime policies of the distributed training
	// job, for example how to clean up resources and how long the job can stay
	// active.
  RunPolicy run_policy = 4;

  // SuccessPolicy defines the policy to mark the TFJob as succeeded. Default to None.
	SuccessPolicy success_policy = 5;
}

message DistributedTensorflowTrainingReplicaSpec {
  // Number of workers
  int32 replicas = 1;

  // Unique name of a PodTemplate k8s resource to be used as the base configuration.
  // PodTemplate specified here will be overriden by the pod template specified at the task metedata level.
  string pod_template_name = 2;

  // Restart policy for the worker
  RestartPolicy restart_policy = 3;
}